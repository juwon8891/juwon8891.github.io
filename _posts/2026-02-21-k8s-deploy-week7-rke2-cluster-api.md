---
layout: post
title: "[K8s-Deploy] Week 7 - RKE2 & Cluster API"
date: 2026-02-21
categories: [K8s-Deploy, Kubernetes, RKE2, Cluster-API, Rancher, CAPI, Infrastructure-as-Code]
---

# [K8s-Deploy] Week 7 - RKE2 & Cluster API

> **Week 7 í•™ìŠµ ì£¼ì œ**: Rancher Governmentì˜ ë³´ì•ˆ ê°•í™” Kubernetes ë°°í¬íŒ RKE2ì™€ ì„ ì–¸ì  í´ëŸ¬ìŠ¤í„° ê´€ë¦¬ë¥¼ ìœ„í•œ Cluster APIë¥¼ í•™ìŠµí•©ë‹ˆë‹¤.

## ğŸ“‹ ëª©ì°¨

1. [ğŸ¯ Week 7 í•™ìŠµ ëª©í‘œ](#-week-7-í•™ìŠµ-ëª©í‘œ)
   - [í•™ìŠµ ëª©í‘œ](#1-í•™ìŠµ-ëª©í‘œ)
   - [ì‹¤ìŠµ í™˜ê²½ êµ¬ì„±](#2-ì‹¤ìŠµ-í™˜ê²½-êµ¬ì„±)

2. [ğŸ” RKE2 ì†Œê°œ](#-rke2-ì†Œê°œ)
   - [RKE2ë€?](#1-rke2ë€)
   - [RKE vs RKE2](#2-rke-vs-rke2)
   - [ì£¼ìš” íŠ¹ì§•](#3-ì£¼ìš”-íŠ¹ì§•)
   - [ë³´ì•ˆ ê°•í™” ê¸°ëŠ¥](#4-ë³´ì•ˆ-ê°•í™”-ê¸°ëŠ¥)

3. [ğŸ—ï¸ RKE2 ì•„í‚¤í…ì²˜](#ï¸-rke2-ì•„í‚¤í…ì²˜)
   - [Server ë…¸ë“œ êµ¬ì„±](#1-server-ë…¸ë“œ-êµ¬ì„±)
   - [Agent ë…¸ë“œ êµ¬ì„±](#2-agent-ë…¸ë“œ-êµ¬ì„±)
   - [ë‚´ì¥ ì»´í¬ë„ŒíŠ¸](#3-ë‚´ì¥-ì»´í¬ë„ŒíŠ¸)
   - [ê³ ê°€ìš©ì„±(HA) êµ¬ì„±](#4-ê³ ê°€ìš©ì„±ha-êµ¬ì„±)

4. [âš™ï¸ RKE2 ì„¤ì¹˜ ë° êµ¬ì„±](#ï¸-rke2-ì„¤ì¹˜-ë°-êµ¬ì„±)
   - [Server ë…¸ë“œ ì„¤ì¹˜](#1-server-ë…¸ë“œ-ì„¤ì¹˜)
   - [Agent ë…¸ë“œ ì„¤ì¹˜](#2-agent-ë…¸ë“œ-ì„¤ì¹˜)
   - [ì„¤ì • íŒŒì¼ êµ¬ì¡°](#3-ì„¤ì •-íŒŒì¼-êµ¬ì¡°)
   - [CNI ì„ íƒ (Cilium)](#4-cni-ì„ íƒ-cilium)

5. [ğŸ”„ RKE2 ì—…ê·¸ë ˆì´ë“œ](#-rke2-ì—…ê·¸ë ˆì´ë“œ)
   - [ìˆ˜ë™ ì—…ê·¸ë ˆì´ë“œ](#1-ìˆ˜ë™-ì—…ê·¸ë ˆì´ë“œ)
   - [Automated ì—…ê·¸ë ˆì´ë“œ (System Upgrade Controller)](#2-automated-ì—…ê·¸ë ˆì´ë“œ-system-upgrade-controller)
   - [ì—…ê·¸ë ˆì´ë“œ ìˆœì„œ](#3-ì—…ê·¸ë ˆì´ë“œ-ìˆœì„œ)

6. [ğŸ“œ RKE2 ì¸ì¦ì„œ ê´€ë¦¬](#-rke2-ì¸ì¦ì„œ-ê´€ë¦¬)
   - [ì¸ì¦ì„œ ìœ„ì¹˜](#1-ì¸ì¦ì„œ-ìœ„ì¹˜)
   - [ì¸ì¦ì„œ ê°±ì‹ ](#2-ì¸ì¦ì„œ-ê°±ì‹ )
   - [Custom CA ì‚¬ìš©](#3-custom-ca-ì‚¬ìš©)

7. [ğŸŒ Cluster API (CAPI) ì†Œê°œ](#-cluster-api-capi-ì†Œê°œ)
   - [Cluster APIë€?](#1-cluster-apië€)
   - [CAPI ì£¼ìš” ê°œë…](#2-capi-ì£¼ìš”-ê°œë…)
   - [CAPI ì•„í‚¤í…ì²˜](#3-capi-ì•„í‚¤í…ì²˜)
   - [Provider ì¢…ë¥˜](#4-provider-ì¢…ë¥˜)

8. [ğŸ”§ Cluster API ì‹¤ìŠµ](#-cluster-api-ì‹¤ìŠµ)
   - [Management Cluster êµ¬ì„±](#1-management-cluster-êµ¬ì„±)
   - [clusterctl ì„¤ì¹˜](#2-clusterctl-ì„¤ì¹˜)
   - [Provider ì´ˆê¸°í™”](#3-provider-ì´ˆê¸°í™”)
   - [Workload Cluster ìƒì„±](#4-workload-cluster-ìƒì„±)
   - [Cluster ê´€ë¦¬](#5-cluster-ê´€ë¦¬)

9. [ğŸ’¡ í•µì‹¬ ê°œë… ì •ë¦¬](#-í•µì‹¬-ê°œë…-ì •ë¦¬)
   - [RKE2ì˜ ë³´ì•ˆ ê°•í™” í¬ì¸íŠ¸](#1-rke2ì˜-ë³´ì•ˆ-ê°•í™”-í¬ì¸íŠ¸)
   - [Cluster APIì˜ ì¥ì ](#2-cluster-apiì˜-ì¥ì )
   - [RKE2 vs K3s vs kubeadm](#3-rke2-vs-k3s-vs-kubeadm)

10. [ğŸ“ Week 7 í•™ìŠµ ì •ë¦¬](#-week-7-í•™ìŠµ-ì •ë¦¬)

---

## ğŸ¯ Week 7 í•™ìŠµ ëª©í‘œ

### 1. í•™ìŠµ ëª©í‘œ

**Week 7**ì—ì„œëŠ” í”„ë¡œë•ì…˜ í™˜ê²½ì—ì„œ ì‚¬ìš© ê°€ëŠ¥í•œ Kubernetes ë°°í¬íŒê³¼ í´ëŸ¬ìŠ¤í„° ê´€ë¦¬ ë„êµ¬ë¥¼ í•™ìŠµí•©ë‹ˆë‹¤.

**ì´ë²ˆ ì£¼ í•µì‹¬ í•™ìŠµ í¬ì¸íŠ¸**:
- âœ… RKE2ì˜ ë³´ì•ˆ ê°•í™” ê¸°ëŠ¥ê³¼ íŠ¹ì§• ì´í•´
- âœ… RKE2 Server/Agent ì•„í‚¤í…ì²˜ êµ¬ì„±
- âœ… RKE2 í´ëŸ¬ìŠ¤í„° ì„¤ì¹˜ ë° êµ¬ì„±
- âœ… RKE2 ì—…ê·¸ë ˆì´ë“œ ì „ëµ (ìˆ˜ë™ vs ìë™)
- âœ… Cluster APIë¥¼ í†µí•œ ì„ ì–¸ì  í´ëŸ¬ìŠ¤í„° ê´€ë¦¬
- âœ… Management Clusterì™€ Workload Cluster ê°œë…
- âœ… Infrastructure Providerë¥¼ í†µí•œ ë©€í‹° í´ë¼ìš°ë“œ ì§€ì›

**ì™œ RKE2ì™€ Cluster APIë¥¼ ë°°ìš°ëŠ”ê°€?**
- **RKE2**: FIPS 140-2, CIS Benchmark ì¤€ìˆ˜ê°€ í•„ìš”í•œ ë³´ì•ˆ ê°•í™” í™˜ê²½
- **Cluster API**: GitOps ê¸°ë°˜ ì„ ì–¸ì  í´ëŸ¬ìŠ¤í„° ê´€ë¦¬ ë° ë©€í‹° í´ë¼ìš°ë“œ í™˜ê²½

### 2. ì‹¤ìŠµ í™˜ê²½ êµ¬ì„±

#### RKE2 ì‹¤ìŠµ í™˜ê²½

**ê°€ìƒë¨¸ì‹  êµ¬ì„±** (VirtualBox, Ubuntu 22.04):

| í˜¸ìŠ¤íŠ¸ëª… | IP ì£¼ì†Œ | ì—­í•  | vCPU | Memory |
|---------|---------|------|------|--------|
| rke2-server1 | 192.168.56.11 | Server (Control Plane) | 2 | 4GB |
| rke2-server2 | 192.168.56.12 | Server (Control Plane) | 2 | 4GB |
| rke2-server3 | 192.168.56.13 | Server (Control Plane) | 2 | 4GB |
| rke2-agent1 | 192.168.56.21 | Agent (Worker) | 2 | 4GB |
| rke2-agent2 | 192.168.56.22 | Agent (Worker) | 2 | 4GB |

**ë„¤íŠ¸ì›Œí¬ ëŒ€ì—­**:
- Cluster CIDR (Pod Network): 10.42.0.0/16
- Service CIDR: 10.43.0.0/16

#### Cluster API ì‹¤ìŠµ í™˜ê²½

**ê°€ìƒë¨¸ì‹  êµ¬ì„±**:

| í˜¸ìŠ¤íŠ¸ëª… | IP ì£¼ì†Œ | ì—­í•  | vCPU | Memory |
|---------|---------|------|------|--------|
| capi-mgmt | 192.168.56.100 | Management Cluster | 2 | 4GB |

**ì»´í¬ë„ŒíŠ¸ ë²„ì „**:
- RKE2: v1.28.x
- Cluster API: v1.6.x
- clusterctl: v1.6.x
- Docker Provider: v1.6.x

---

## ğŸ” RKE2 ì†Œê°œ

### 1. RKE2ë€?

**RKE2 (RKE Government)** = **Rancher Kubernetes Engine 2**

- Rancherì—ì„œ ê°œë°œí•œ **ë³´ì•ˆ ê°•í™”** Kubernetes ë°°í¬íŒ
- **ë¯¸êµ­ ì—°ë°© ì •ë¶€** ìš”êµ¬ì‚¬í•­ ì¶©ì¡± (FIPS 140-2, STIG)
- **CIS Kubernetes Benchmark** ê¸°ë³¸ ì¤€ìˆ˜
- RKE1ì˜ í›„ì† ë²„ì „ (ì™„ì „íˆ ë‹¤ì‹œ ì‘ì„±)

### 2. RKE vs RKE2

| íŠ¹ì§• | RKE1 | RKE2 |
|------|------|------|
| **ë°°í¬ ë°©ì‹** | Docker ì»¨í…Œì´ë„ˆ ê¸°ë°˜ | systemd ì„œë¹„ìŠ¤ ê¸°ë°˜ |
| **Container Runtime** | Docker | containerd (ê¸°ë³¸) |
| **ì„¤ì¹˜ ë°©ë²•** | rke CLI | ë°”ì´ë„ˆë¦¬ ì„¤ì¹˜ |
| **ë³´ì•ˆ ì¤€ìˆ˜** | ì„ íƒì  | ê¸°ë³¸ ê°•í™” (FIPS, CIS) |
| **etcd** | Docker ì»¨í…Œì´ë„ˆ | Static Pod |
| **Control Plane** | Docker ì»¨í…Œì´ë„ˆ | Static Pod |

### 3. ì£¼ìš” íŠ¹ì§•

#### 3.1 Security First
```bash
# FIPS 140-2 ì¤€ìˆ˜ ì•”í˜¸í™” ëª¨ë“ˆ ì‚¬ìš©
# - TLS 1.2+ ê°•ì œ
# - ìŠ¹ì¸ëœ ì•”í˜¸í™” ì•Œê³ ë¦¬ì¦˜ë§Œ ì‚¬ìš©
# - NIST í‘œì¤€ ì¤€ìˆ˜
```

#### 3.2 ë‚´ì¥ ì»´í¬ë„ŒíŠ¸
- **CNI**: Canal (Calico + Flannel) ê¸°ë³¸, Cilium/Calico/Multus ì„ íƒ ê°€ëŠ¥
- **Ingress Controller**: Nginx Ingress Controller
- **Service Load Balancer**: Klipper LB (ê°œë°œ í™˜ê²½ìš©)
- **Metrics Server**: ê¸°ë³¸ í¬í•¨
- **CoreDNS**: DNS ì„œë²„

#### 3.3 ê°„í¸í•œ ì„¤ì¹˜
```bash
# Server ë…¸ë“œ ì„¤ì¹˜ (ë‹¨ì¼ ëª…ë ¹)
curl -sfL https://get.rke2.io | sh -
systemctl enable rke2-server.service
systemctl start rke2-server.service

# Agent ë…¸ë“œ ì„¤ì¹˜
curl -sfL https://get.rke2.io | INSTALL_RKE2_TYPE="agent" sh -
systemctl enable rke2-agent.service
systemctl start rke2-agent.service
```

### 4. ë³´ì•ˆ ê°•í™” ê¸°ëŠ¥

#### 4.1 CIS Hardened
```yaml
# /etc/rancher/rke2/config.yaml
# CIS Profile ìë™ ì ìš©
profile: cis-1.23

# ìë™ìœ¼ë¡œ ì ìš©ë˜ëŠ” ì„¤ì •:
# - Pod Security Standards (Restricted)
# - Network Policies í™œì„±í™”
# - Audit Logging í™œì„±í™”
# - ì•ˆì „í•œ kubelet ì„¤ì •
```

#### 4.2 SELinux/AppArmor ì§€ì›
```bash
# SELinux (RHEL/CentOS)
setenforce 1
# RKE2ê°€ ìë™ìœ¼ë¡œ SELinux ì •ì±… ì ìš©

# AppArmor (Ubuntu/Debian)
# RKE2ê°€ ìë™ìœ¼ë¡œ AppArmor í”„ë¡œí•„ ë¡œë“œ
```

#### 4.3 FIPS 140-2 ëª¨ë“œ
```bash
# FIPS ëª¨ë“œ í™œì„±í™”
export INSTALL_RKE2_FIPS=true
curl -sfL https://get.rke2.io | sh -

# ê²€ì¦
rke2 --version
# rke2 version v1.28.x+rke2r1-fips
```

---

## ğŸ—ï¸ RKE2 ì•„í‚¤í…ì²˜

### 1. Server ë…¸ë“œ êµ¬ì„±

**Server ë…¸ë“œ** = Control Plane ë…¸ë“œ

#### ì»´í¬ë„ŒíŠ¸ êµ¬ì„±

```mermaid
graph TB
    subgraph "RKE2 Server Node"
        subgraph "systemd"
            RKE2S[rke2-server.service]
        end

        subgraph "Static Pods"
            ETCD[etcd]
            API[kube-apiserver]
            CM[kube-controller-manager]
            SCHED[kube-scheduler]
            CP[cloud-provider]
        end

        subgraph "Containerd"
            CONT[containerd]
            CNI[CNI Plugin<br/>Canal/Cilium]
            KUBELET[kubelet]
            PROXY[kube-proxy]
        end

        subgraph "Add-ons"
            NGINX[nginx-ingress]
            METRICS[metrics-server]
            COREDNS[coredns]
        end
    end

    RKE2S --> CONT
    RKE2S --> ETCD
    RKE2S --> API
    RKE2S --> CM
    RKE2S --> SCHED
    CONT --> KUBELET
    CONT --> CNI
    KUBELET --> PROXY
    KUBELET --> NGINX
    KUBELET --> METRICS
    KUBELET --> COREDNS
```

**ì£¼ìš” ë””ë ‰í„°ë¦¬**:
```bash
/var/lib/rancher/rke2/
â”œâ”€â”€ agent/              # kubelet, containerd ë°ì´í„°
â”œâ”€â”€ bin/                # Kubernetes ë°”ì´ë„ˆë¦¬
â”œâ”€â”€ server/
â”‚   â”œâ”€â”€ manifests/      # Static Pod ë§¤ë‹ˆí˜ìŠ¤íŠ¸
â”‚   â”œâ”€â”€ tls/            # ì¸ì¦ì„œ
â”‚   â””â”€â”€ token           # Node Join Token
â””â”€â”€ etc/                # ì„¤ì • íŒŒì¼
```

### 2. Agent ë…¸ë“œ êµ¬ì„±

**Agent ë…¸ë“œ** = Worker ë…¸ë“œ

#### ì»´í¬ë„ŒíŠ¸ êµ¬ì„±

```mermaid
graph TB
    subgraph "RKE2 Agent Node"
        subgraph "systemd"
            RKE2A[rke2-agent.service]
        end

        subgraph "Containerd"
            CONT[containerd]
            CNI[CNI Plugin]
            KUBELET[kubelet]
            PROXY[kube-proxy]
        end

        subgraph "Workloads"
            POD1[Pod 1]
            POD2[Pod 2]
            POD3[Pod 3]
        end
    end

    RKE2A --> CONT
    RKE2A --> KUBELET
    KUBELET --> CNI
    KUBELET --> PROXY
    KUBELET --> POD1
    KUBELET --> POD2
    KUBELET --> POD3
```

### 3. ë‚´ì¥ ì»´í¬ë„ŒíŠ¸

#### 3.1 CNI ì˜µì…˜

```yaml
# /etc/rancher/rke2/config.yaml

# ì˜µì…˜ 1: Canal (ê¸°ë³¸ê°’)
cni: canal

# ì˜µì…˜ 2: Cilium (eBPF ê¸°ë°˜, ê³ ì„±ëŠ¥)
cni: cilium

# ì˜µì…˜ 3: Calico (NetworkPolicy ê°•ë ¥)
cni: calico

# ì˜µì…˜ 4: Multus (Multi-NIC)
cni: multus,canal

# ì˜µì…˜ 5: CNI ì—†ìŒ (ìˆ˜ë™ ì„¤ì¹˜)
cni: none
```

#### 3.2 Ingress Controller

```yaml
# nginx-ingress (ê¸°ë³¸ í¬í•¨)
# - NodePort 30080 (HTTP), 30443 (HTTPS)
# - HostPort 80, 443 (Bare-Metal)

# ë¹„í™œì„±í™”
disable: rke2-ingress-nginx
```

#### 3.3 Service LoadBalancer

```yaml
# Klipper LB (ê°œë°œ í™˜ê²½ìš©)
# - NodePortë¥¼ í˜¸ìŠ¤íŠ¸ í¬íŠ¸ë¡œ í¬ì›Œë”©
# - LoadBalancer Service ì§€ì›

# ë¹„í™œì„±í™” (MetalLB ë“± ì‚¬ìš© ì‹œ)
disable: rke2-servicelb
```

### 4. ê³ ê°€ìš©ì„±(HA) êµ¬ì„±

#### 4.1 Embedded etcd (ê¶Œì¥)

```mermaid
graph TB
    subgraph "HA RKE2 Cluster"
        LB[Load Balancer<br/>192.168.56.10:9345]

        subgraph "Server 1"
            S1[rke2-server]
            E1[etcd]
        end

        subgraph "Server 2"
            S2[rke2-server]
            E2[etcd]
        end

        subgraph "Server 3"
            S3[rke2-server]
            E3[etcd]
        end

        A1[Agent 1]
        A2[Agent 2]
    end

    LB -.->|9345| S1
    LB -.->|9345| S2
    LB -.->|9345| S3

    E1 <-->|Raft| E2
    E2 <-->|Raft| E3
    E3 <-->|Raft| E1

    A1 -->|Join| LB
    A2 -->|Join| LB
```

**ì„¤ì •**:
```yaml
# Server 1 (First Node)
# /etc/rancher/rke2/config.yaml
cluster-init: true
tls-san:
  - rke2-server1
  - 192.168.56.11
  - 192.168.56.10  # VIP/LB

# Server 2, 3 (Additional Nodes)
# /etc/rancher/rke2/config.yaml
server: https://192.168.56.11:9345
token: K10xxx::server:yyy  # Server 1ì˜ í† í°
tls-san:
  - rke2-server2  # ê° ë…¸ë“œëª…
  - 192.168.56.12  # ê° ë…¸ë“œ IP
  - 192.168.56.10  # ê³µí†µ VIP/LB
```

#### 4.2 ì™¸ë¶€ Datastore (PostgreSQL/MySQL)

```yaml
# /etc/rancher/rke2/config.yaml
datastore-endpoint: "postgres://user:pass@host:5432/dbname"
# ë˜ëŠ”
datastore-endpoint: "mysql://user:pass@tcp(host:3306)/dbname"
```

---

## âš™ï¸ RKE2 ì„¤ì¹˜ ë° êµ¬ì„±

### 1. Server ë…¸ë“œ ì„¤ì¹˜

#### 1.1 ì‹œìŠ¤í…œ ì¤€ë¹„

```bash
# ë°©í™”ë²½ í¬íŠ¸ ì˜¤í”ˆ
firewall-cmd --permanent --add-port=6443/tcp  # K8s API
firewall-cmd --permanent --add-port=9345/tcp  # RKE2 Supervisor
firewall-cmd --permanent --add-port=10250/tcp # Kubelet
firewall-cmd --permanent --add-port=2379-2380/tcp  # etcd
firewall-cmd --reload

# SELinux Permissive (ì„ íƒ)
setenforce 0
sed -i 's/^SELINUX=enforcing$/SELINUX=permissive/' /etc/selinux/config

# Swap ë¹„í™œì„±í™”
swapoff -a
sed -i '/ swap / s/^/#/' /etc/fstab
```

#### 1.2 RKE2 ì„¤ì¹˜

```bash
# RKE2 ì„¤ì¹˜ ìŠ¤í¬ë¦½íŠ¸ ë‹¤ìš´ë¡œë“œ ë° ì‹¤í–‰
curl -sfL https://get.rke2.io | sh -

# ì„¤ì¹˜ í™•ì¸
ls -l /usr/local/bin/rke2
rke2 --version
```

#### 1.3 ì„¤ì • íŒŒì¼ ì‘ì„±

```bash
# /etc/rancher/rke2/config.yaml
mkdir -p /etc/rancher/rke2
cat > /etc/rancher/rke2/config.yaml <<EOF
# Server ì„¤ì •
write-kubeconfig-mode: "0644"
tls-san:
  - "rke2-server1"
  - "192.168.56.11"

# CNI ì„ íƒ
cni: cilium

# CIS Profile (ì„ íƒ)
profile: cis-1.23

# Add-on ë¹„í™œì„±í™” (ì„ íƒ)
# disable:
#   - rke2-ingress-nginx
#   - rke2-servicelb

# Node ì„¤ì •
node-label:
  - "node-role=control-plane"
node-taint:
  - "node-role.kubernetes.io/control-plane=true:NoSchedule"
EOF
```

#### 1.4 RKE2 ì‹œì‘

```bash
# systemd ì„œë¹„ìŠ¤ í™œì„±í™” ë° ì‹œì‘
systemctl enable rke2-server.service
systemctl start rke2-server.service

# ë¡œê·¸ í™•ì¸
journalctl -u rke2-server -f

# ìƒíƒœ í™•ì¸
systemctl status rke2-server.service
```

#### 1.5 kubectl ì„¤ì •

```bash
# kubeconfig ë³µì‚¬
mkdir -p ~/.kube
cp /etc/rancher/rke2/rke2.yaml ~/.kube/config

# kubectl ì‹¬ë³¼ë¦­ ë§í¬
ln -s /var/lib/rancher/rke2/bin/kubectl /usr/local/bin/kubectl

# í™•ì¸
kubectl get nodes
kubectl get pods -A
```

#### 1.6 Node Token í™•ì¸

```bash
# Agent ë…¸ë“œ Joinì— í•„ìš”í•œ Token
cat /var/lib/rancher/rke2/server/node-token
# ì˜ˆ: K10xxx::server:yyy

# ë˜ëŠ”
cat /var/lib/rancher/rke2/server/token
```

### 2. Agent ë…¸ë“œ ì„¤ì¹˜

#### 2.1 RKE2 Agent ì„¤ì¹˜

```bash
# Agent íƒ€ì…ìœ¼ë¡œ ì„¤ì¹˜
curl -sfL https://get.rke2.io | INSTALL_RKE2_TYPE="agent" sh -

# ì„¤ì¹˜ í™•ì¸
ls -l /usr/local/bin/rke2
```

#### 2.2 ì„¤ì • íŒŒì¼ ì‘ì„±

```bash
# /etc/rancher/rke2/config.yaml
mkdir -p /etc/rancher/rke2
cat > /etc/rancher/rke2/config.yaml <<EOF
# Server ì£¼ì†Œ
server: https://192.168.56.11:9345

# Node Token (Serverì—ì„œ ë³µì‚¬)
token: K10xxx::server:yyy

# Node ì„¤ì •
node-label:
  - "node-role=worker"
EOF
```

#### 2.3 RKE2 Agent ì‹œì‘

```bash
# systemd ì„œë¹„ìŠ¤ í™œì„±í™” ë° ì‹œì‘
systemctl enable rke2-agent.service
systemctl start rke2-agent.service

# ë¡œê·¸ í™•ì¸
journalctl -u rke2-agent -f

# ìƒíƒœ í™•ì¸
systemctl status rke2-agent.service
```

#### 2.4 ë…¸ë“œ í™•ì¸ (Serverì—ì„œ)

```bash
kubectl get nodes
# NAME           STATUS   ROLES                       AGE   VERSION
# rke2-server1   Ready    control-plane,etcd,master   10m   v1.28.x+rke2r1
# rke2-agent1    Ready    <none>                      2m    v1.28.x+rke2r1
```

### 3. ì„¤ì • íŒŒì¼ êµ¬ì¡°

#### 3.1 ì£¼ìš” ì„¤ì • ì˜µì…˜

```yaml
# /etc/rancher/rke2/config.yaml

# === Server ì „ìš© ì˜µì…˜ ===
# í´ëŸ¬ìŠ¤í„° ì´ˆê¸°í™” (ì²« ë²ˆì§¸ Serverë§Œ)
cluster-init: true

# ì¶”ê°€ Serverê°€ Joiní•  ì£¼ì†Œ (ë‘ ë²ˆì§¸ Serverë¶€í„°)
server: https://192.168.56.11:9345

# etcd ìŠ¤ëƒ…ìƒ· (ë°±ì—…)
etcd-snapshot-schedule-cron: "0 */6 * * *"  # 6ì‹œê°„ë§ˆë‹¤
etcd-snapshot-retention: 10  # 10ê°œ ìœ ì§€

# === Server/Agent ê³µí†µ ì˜µì…˜ ===
# Node Token
token: K10xxx::server:yyy

# TLS SAN (ì¶”ê°€ ì¸ì¦ì„œ ì£¼ì²´ ëŒ€ì²´ ì´ë¦„)
tls-san:
  - "192.168.56.10"  # VIP
  - "rke2.example.com"

# kubeconfig ê¶Œí•œ
write-kubeconfig-mode: "0644"

# CNI ì„ íƒ
cni:
  - cilium

# Node ì„¤ì •
node-name: "custom-node-name"
node-label:
  - "key=value"
node-taint:
  - "key=value:NoSchedule"

# CIS Profile
profile: cis-1.23

# Kubelet ì˜µì…˜
kubelet-arg:
  - "max-pods=200"
  - "eviction-hard=memory.available<500Mi"

# Kube-APIServer ì˜µì…˜
kube-apiserver-arg:
  - "audit-log-path=/var/log/kubernetes/audit.log"
  - "audit-log-maxage=30"

# Add-on ë¹„í™œì„±í™”
disable:
  - rke2-ingress-nginx
  - rke2-metrics-server
```

### 4. CNI ì„ íƒ (Cilium)

#### 4.1 Cilium ì„¤ì •

```yaml
# /etc/rancher/rke2/config.yaml
cni: cilium
```

#### 4.2 Cilium í™•ì¸

```bash
# Cilium Pods í™•ì¸
kubectl get pods -n kube-system -l k8s-app=cilium

# Cilium CLI ì„¤ì¹˜
CILIUM_CLI_VERSION=$(curl -s https://raw.githubusercontent.com/cilium/cilium-cli/main/stable.txt)
curl -L --remote-name-all https://github.com/cilium/cilium-cli/releases/download/${CILIUM_CLI_VERSION}/cilium-linux-amd64.tar.gz
tar xzvf cilium-linux-amd64.tar.gz
sudo mv cilium /usr/local/bin/

# Cilium ìƒíƒœ í™•ì¸
cilium status
cilium connectivity test
```

---

## ğŸ”„ RKE2 ì—…ê·¸ë ˆì´ë“œ

### 1. ìˆ˜ë™ ì—…ê·¸ë ˆì´ë“œ

#### 1.1 ì—…ê·¸ë ˆì´ë“œ íë¦„

```mermaid
graph LR
    A[í˜„ì¬ ë²„ì „<br/>v1.28.5] --> B[Server 1<br/>Upgrade]
    B --> C[Server 2<br/>Upgrade]
    C --> D[Server 3<br/>Upgrade]
    D --> E[Agent 1<br/>Upgrade]
    E --> F[Agent 2<br/>Upgrade]
    F --> G[ì™„ë£Œ<br/>v1.28.8]
```

#### 1.2 Server ë…¸ë“œ ì—…ê·¸ë ˆì´ë“œ

```bash
# 1. ì—…ê·¸ë ˆì´ë“œí•  ë²„ì „ í™•ì¸
curl -s https://update.rke2.io/v1-release/channels | jq -r '.data[] | select(.id=="stable") | .latest'

# 2. Server ë…¸ë“œ ì—…ê·¸ë ˆì´ë“œ (í•œ ë²ˆì— 1ê°œì”©!)
# Server 1
systemctl stop rke2-server
curl -sfL https://get.rke2.io | INSTALL_RKE2_VERSION=v1.28.8+rke2r1 sh -
systemctl start rke2-server

# 3. í™•ì¸
kubectl get nodes
journalctl -u rke2-server -f

# 4. Server 2, 3ë„ ë™ì¼í•˜ê²Œ ìˆœì°¨ ì—…ê·¸ë ˆì´ë“œ
```

#### 1.3 Agent ë…¸ë“œ ì—…ê·¸ë ˆì´ë“œ

```bash
# Agent ë…¸ë“œ ì—…ê·¸ë ˆì´ë“œ (í•œ ë²ˆì— 1ê°œì”© ë˜ëŠ” Rolling)
systemctl stop rke2-agent
curl -sfL https://get.rke2.io | INSTALL_RKE2_TYPE="agent" INSTALL_RKE2_VERSION=v1.28.8+rke2r1 sh -
systemctl start rke2-agent

# í™•ì¸
kubectl get nodes
```

### 2. Automated ì—…ê·¸ë ˆì´ë“œ (System Upgrade Controller)

#### 2.1 System Upgrade Controller ì„¤ì¹˜

```bash
# SUC ì„¤ì¹˜
kubectl apply -f https://github.com/rancher/system-upgrade-controller/releases/latest/download/system-upgrade-controller.yaml

# í™•ì¸
kubectl get pods -n system-upgrade
```

#### 2.2 Server ì—…ê·¸ë ˆì´ë“œ Plan

```yaml
# server-plan.yaml
apiVersion: upgrade.cattle.io/v1
kind: Plan
metadata:
  name: server-plan
  namespace: system-upgrade
spec:
  # ë™ì‹œ ì—…ê·¸ë ˆì´ë“œ ë…¸ë“œ ìˆ˜
  concurrency: 1

  # Server ë…¸ë“œ ì„ íƒ
  nodeSelector:
    matchExpressions:
      - key: node-role.kubernetes.io/control-plane
        operator: Exists

  # RKE2 ì„œë¹„ìŠ¤ ì´ë¦„
  serviceAccountName: system-upgrade

  # Cordon & Drain
  cordon: true
  drain:
    force: true
    skipWaitForDeleteTimeout: 60

  # ì—…ê·¸ë ˆì´ë“œ ëŒ€ìƒ ë²„ì „
  version: v1.28.8+rke2r1

  # ì—…ê·¸ë ˆì´ë“œ ìŠ¤í¬ë¦½íŠ¸
  upgrade:
    image: rancher/rke2-upgrade
```

#### 2.3 Agent ì—…ê·¸ë ˆì´ë“œ Plan

```yaml
# agent-plan.yaml
apiVersion: upgrade.cattle.io/v1
kind: Plan
metadata:
  name: agent-plan
  namespace: system-upgrade
spec:
  concurrency: 2  # ë™ì‹œ 2ê°œ

  # Agent ë…¸ë“œ ì„ íƒ
  nodeSelector:
    matchExpressions:
      - key: node-role.kubernetes.io/control-plane
        operator: DoesNotExist

  serviceAccountName: system-upgrade

  # Server ì—…ê·¸ë ˆì´ë“œ ì™„ë£Œ í›„ ì‹¤í–‰
  prepare:
    image: rancher/rke2-upgrade
    args: ["prepare", "server-plan"]

  cordon: true
  drain:
    force: true
    skipWaitForDeleteTimeout: 60

  version: v1.28.8+rke2r1

  upgrade:
    image: rancher/rke2-upgrade
```

#### 2.4 ì—…ê·¸ë ˆì´ë“œ ì‹¤í–‰

```bash
# Plan ì ìš©
kubectl apply -f server-plan.yaml
kubectl apply -f agent-plan.yaml

# ì—…ê·¸ë ˆì´ë“œ ì§„í–‰ ëª¨ë‹ˆí„°ë§
kubectl get plans -n system-upgrade
kubectl get jobs -n system-upgrade
kubectl logs -n system-upgrade -l upgrade.cattle.io/plan=server-plan -f

# ë…¸ë“œ ìƒíƒœ í™•ì¸
kubectl get nodes -w
```

### 3. ì—…ê·¸ë ˆì´ë“œ ìˆœì„œ

```mermaid
graph TB
    START[ì—…ê·¸ë ˆì´ë“œ ì‹œì‘] --> BACKUP[etcd ë°±ì—…]
    BACKUP --> S1[Server 1 ì—…ê·¸ë ˆì´ë“œ]
    S1 --> S1C{Server 1<br/>ì •ìƒ?}
    S1C -->|Yes| S2[Server 2 ì—…ê·¸ë ˆì´ë“œ]
    S1C -->|No| ROLLBACK[Rollback]
    S2 --> S2C{Server 2<br/>ì •ìƒ?}
    S2C -->|Yes| S3[Server 3 ì—…ê·¸ë ˆì´ë“œ]
    S2C -->|No| ROLLBACK
    S3 --> S3C{Server 3<br/>ì •ìƒ?}
    S3C -->|Yes| AGENT[Agent ì—…ê·¸ë ˆì´ë“œ<br/>ë™ì‹œ 1-2ê°œ]
    S3C -->|No| ROLLBACK
    AGENT --> VERIFY[ê²€ì¦ ë° ì™„ë£Œ]
```

**ì—…ê·¸ë ˆì´ë“œ Best Practices**:
1. **etcd ë°±ì—… í•„ìˆ˜**
2. **Server ë…¸ë“œ ë¨¼ì €**, í•œ ë²ˆì— 1ê°œì”©
3. **ê° Server ì—…ê·¸ë ˆì´ë“œ í›„ ì •ìƒ ë™ì‘ í™•ì¸**
4. **Agent ë…¸ë“œ ë‚˜ì¤‘**, ë™ì‹œ 1-2ê°œ
5. **Drain & Cordonìœ¼ë¡œ ì›Œí¬ë¡œë“œ ì•ˆì „í•˜ê²Œ ì´ë™**

---

## ğŸ“œ RKE2 ì¸ì¦ì„œ ê´€ë¦¬

### 1. ì¸ì¦ì„œ ìœ„ì¹˜

```bash
# ì¸ì¦ì„œ ì €ì¥ ìœ„ì¹˜
/var/lib/rancher/rke2/server/tls/

# ì£¼ìš” ì¸ì¦ì„œ
â”œâ”€â”€ server-ca.crt               # Server CA
â”œâ”€â”€ server-ca.key
â”œâ”€â”€ client-ca.crt               # Client CA
â”œâ”€â”€ client-ca.key
â”œâ”€â”€ request-header-ca.crt       # Request Header CA
â”œâ”€â”€ request-header-ca.key
â”œâ”€â”€ serving-kube-apiserver.crt  # API Server ì„œë¹™
â”œâ”€â”€ serving-kube-apiserver.key
â”œâ”€â”€ client-kube-apiserver.crt   # API Server í´ë¼ì´ì–¸íŠ¸
â”œâ”€â”€ client-admin.crt            # Admin í´ë¼ì´ì–¸íŠ¸
â””â”€â”€ ...
```

### 2. ì¸ì¦ì„œ ê°±ì‹ 

#### 2.1 ìë™ ê°±ì‹ 

```bash
# RKE2ëŠ” ì¸ì¦ì„œë¥¼ ìë™ìœ¼ë¡œ ê°±ì‹  (ë§Œë£Œ 90ì¼ ì „)
# - rke2-server ì¬ì‹œì‘ ì‹œ ìë™ ì²´í¬
# - ë§Œë£Œ ì„ë°• ì‹œ ìë™ ê°±ì‹ 

# ìˆ˜ë™ ê°±ì‹  íŠ¸ë¦¬ê±° (ì¬ì‹œì‘)
systemctl restart rke2-server
```

#### 2.2 ì¸ì¦ì„œ í™•ì¸

```bash
# API Server ì¸ì¦ì„œ ë§Œë£Œì¼ í™•ì¸
openssl x509 -in /var/lib/rancher/rke2/server/tls/serving-kube-apiserver.crt -noout -enddate
# notAfter=Feb 21 12:00:00 2027 GMT

# ëª¨ë“  ì¸ì¦ì„œ ë§Œë£Œì¼ í™•ì¸
for cert in /var/lib/rancher/rke2/server/tls/*.crt; do
  echo "=== $cert ==="
  openssl x509 -in $cert -noout -enddate
done
```

### 3. Custom CA ì‚¬ìš©

#### 3.1 ê¸°ì¡´ CAë¡œ ì„œëª…ëœ ì¸ì¦ì„œ ì‚¬ìš©

```bash
# /etc/rancher/rke2/config.yaml
# (í˜„ì¬ RKE2ëŠ” Custom CA ì§ì ‘ ì§€ì› ì œí•œì )
# Workaround: cert-manager ì‚¬ìš©

# 1. RKE2 ì„¤ì¹˜ ì „ ê¸°ì¡´ ì¸ì¦ì„œ ë°°ì¹˜
mkdir -p /var/lib/rancher/rke2/server/tls/
cp custom-ca.crt /var/lib/rancher/rke2/server/tls/server-ca.crt
cp custom-ca.key /var/lib/rancher/rke2/server/tls/server-ca.key

# 2. RKE2 ì‹œì‘ (ê¸°ì¡´ CA ì‚¬ìš©)
systemctl start rke2-server
```

---

## ğŸŒ Cluster API (CAPI) ì†Œê°œ

### 1. Cluster APIë€?

**Cluster API (CAPI)** = Kubernetesë¥¼ ì‚¬ìš©í•˜ì—¬ Kubernetes í´ëŸ¬ìŠ¤í„°ë¥¼ ê´€ë¦¬í•˜ëŠ” í”„ë¡œì íŠ¸

- **ì„ ì–¸ì  API**: Kubernetes ë¦¬ì†ŒìŠ¤ë¡œ í´ëŸ¬ìŠ¤í„° ì •ì˜
- **GitOps ì¹œí™”ì **: YAML ê¸°ë°˜ Infrastructure as Code
- **ë©€í‹° í´ë¼ìš°ë“œ**: AWS, Azure, GCP, vSphere, OpenStack ë“± ì§€ì›
- **ì¼ê´€ëœ ê²½í—˜**: ëª¨ë“  ì¸í”„ë¼ì—ì„œ ë™ì¼í•œ API ì‚¬ìš©

### 2. CAPI ì£¼ìš” ê°œë…

#### 2.1 Management Cluster vs Workload Cluster

```mermaid
graph TB
    subgraph "Management Cluster"
        CAPI[Cluster API<br/>Controllers]
        CAPA[Infrastructure Provider<br/>AWS/Azure/etc]
    end

    subgraph "Workload Cluster 1"
        WC1[Kubernetes Cluster]
    end

    subgraph "Workload Cluster 2"
        WC2[Kubernetes Cluster]
    end

    CAPI -->|Create/Manage| WC1
    CAPI -->|Create/Manage| WC2
    CAPA -->|Provision| WC1
    CAPA -->|Provision| WC2
```

- **Management Cluster**: Cluster API ì»¨íŠ¸ë¡¤ëŸ¬ê°€ ì‹¤í–‰ë˜ëŠ” í´ëŸ¬ìŠ¤í„°
- **Workload Cluster**: ê´€ë¦¬ ëŒ€ìƒ í´ëŸ¬ìŠ¤í„° (ì‹¤ì œ ì›Œí¬ë¡œë“œ ì‹¤í–‰)

#### 2.2 ì£¼ìš” ë¦¬ì†ŒìŠ¤

| ë¦¬ì†ŒìŠ¤ | ì„¤ëª… | ì˜ˆì‹œ |
|--------|------|------|
| **Cluster** | í´ëŸ¬ìŠ¤í„° ì „ì²´ ì •ì˜ | í´ëŸ¬ìŠ¤í„° ì´ë¦„, ë„¤íŠ¸ì›Œí¬ CIDR |
| **Machine** | ë‹¨ì¼ ë…¸ë“œ (VM/ì¸ìŠ¤í„´ìŠ¤) | Control Plane ë…¸ë“œ, Worker ë…¸ë“œ |
| **MachineDeployment** | ë…¸ë“œ ê·¸ë£¹ (ReplicaSet ìœ ì‚¬) | 3ê°œì˜ Worker ë…¸ë“œ |
| **MachineSet** | Machineì˜ ReplicaSet | Auto-scaling |
| **KubeadmControlPlane** | Control Plane ë…¸ë“œ ê·¸ë£¹ | HA Control Plane |
| **InfrastructureTemplate** | ì¸í”„ë¼ë³„ ì„¤ì • | AWS EC2 ì¸ìŠ¤í„´ìŠ¤ íƒ€ì… |

### 3. CAPI ì•„í‚¤í…ì²˜

```mermaid
graph TB
    subgraph "User"
        USER[kubectl apply<br/>cluster.yaml]
    end

    subgraph "Management Cluster"
        API[Kube-APIServer]

        subgraph "CAPI Controllers"
            CC[Cluster Controller]
            MC[Machine Controller]
            KCP[KubeadmControlPlane<br/>Controller]
        end

        subgraph "Provider Controllers"
            INFRA[Infrastructure Provider<br/>AWS/Docker/etc]
            BOOT[Bootstrap Provider<br/>Kubeadm]
            CP[Control Plane Provider<br/>Kubeadm]
        end
    end

    subgraph "Infrastructure (AWS/vSphere/etc)"
        VM1[VM 1<br/>Control Plane]
        VM2[VM 2<br/>Worker]
    end

    USER --> API
    API --> CC
    API --> MC
    API --> KCP

    CC --> INFRA
    MC --> INFRA
    KCP --> INFRA
    KCP --> BOOT
    KCP --> CP

    INFRA -->|Provision| VM1
    INFRA -->|Provision| VM2
    BOOT -->|cloud-init| VM1
    BOOT -->|cloud-init| VM2
```

### 4. Provider ì¢…ë¥˜

#### 4.1 Infrastructure Providers

| Provider | ì„¤ëª… | í™˜ê²½ |
|----------|------|------|
| **CAPA** | AWS Provider | AWS EC2 |
| **CAPZ** | Azure Provider | Azure VM |
| **CAPG** | GCP Provider | GCP GCE |
| **CAPV** | vSphere Provider | VMware vSphere |
| **CAPO** | OpenStack Provider | OpenStack |
| **CAPD** | Docker Provider | Docker ì»¨í…Œì´ë„ˆ (ê°œë°œ/í…ŒìŠ¤íŠ¸) |

#### 4.2 Bootstrap Providers

- **Kubeadm**: kubeadmì„ ì‚¬ìš©í•œ í´ëŸ¬ìŠ¤í„° ë¶€íŠ¸ìŠ¤íŠ¸ë© (ê¸°ë³¸)
- **Talos**: Talos Linux ì‚¬ìš©

#### 4.3 Control Plane Providers

- **Kubeadm**: kubeadm ê¸°ë°˜ Control Plane ê´€ë¦¬ (ê¸°ë³¸)
- **Kamaji**: ë©€í‹° í…Œë„ŒíŠ¸ Control Plane
- **K3s**: K3s Control Plane
- **RKE2**: RKE2 Control Plane

---

## ğŸ”§ Cluster API ì‹¤ìŠµ

### 1. Management Cluster êµ¬ì„±

#### 1.1 Kindë¡œ Management Cluster ìƒì„±

```bash
# Kind ì„¤ì¹˜
curl -Lo ./kind https://kind.sigs.k8s.io/dl/v0.20.0/kind-linux-amd64
chmod +x ./kind
sudo mv ./kind /usr/local/bin/kind

# Management Cluster ìƒì„±
kind create cluster --name capi-mgmt

# í™•ì¸
kubectl cluster-info
kubectl get nodes
```

### 2. clusterctl ì„¤ì¹˜

```bash
# clusterctl ì„¤ì¹˜
curl -L https://github.com/kubernetes-sigs/cluster-api/releases/download/v1.6.0/clusterctl-linux-amd64 -o clusterctl
chmod +x ./clusterctl
sudo mv ./clusterctl /usr/local/bin/clusterctl

# í™•ì¸
clusterctl version
# clusterctl version: &version.Info{Major:"1", Minor:"6", GitVersion:"v1.6.0"}
```

### 3. Provider ì´ˆê¸°í™”

#### 3.1 Docker Provider ì´ˆê¸°í™” (ë¡œì»¬ í…ŒìŠ¤íŠ¸ìš©)

```bash
# Docker Provider ì´ˆê¸°í™”
clusterctl init --infrastructure docker

# ì„¤ì¹˜ëœ Provider í™•ì¸
clusterctl config provider
kubectl get pods -n capi-system
kubectl get pods -n capi-kubeadm-bootstrap-system
kubectl get pods -n capi-kubeadm-control-plane-system
kubectl get pods -n capd-system
```

#### 3.2 AWS Provider ì´ˆê¸°í™” (í”„ë¡œë•ì…˜ ì˜ˆì‹œ)

```bash
# AWS ìê²©ì¦ëª… ì„¤ì •
export AWS_REGION=us-east-1
export AWS_ACCESS_KEY_ID=xxx
export AWS_SECRET_ACCESS_KEY=yyy
export AWS_B64ENCODED_CREDENTIALS=$(clusterawsadm bootstrap credentials encode-as-profile)

# AWS Provider ì´ˆê¸°í™”
clusterctl init --infrastructure aws

# í™•ì¸
kubectl get pods -n capa-system
```

### 4. Workload Cluster ìƒì„±

#### 4.1 í´ëŸ¬ìŠ¤í„° í…œí”Œë¦¿ ìƒì„± (Docker Provider)

```bash
# í´ëŸ¬ìŠ¤í„° YAML ìƒì„±
export CLUSTER_NAME="capi-quickstart"
export KUBERNETES_VERSION="v1.28.0"

clusterctl generate cluster ${CLUSTER_NAME} \
  --kubernetes-version ${KUBERNETES_VERSION} \
  --control-plane-machine-count=1 \
  --worker-machine-count=2 \
  > capi-quickstart.yaml
```

#### 4.2 ìƒì„±ëœ YAML í™•ì¸

```yaml
# capi-quickstart.yaml (ê°„ëµí™”)
---
apiVersion: cluster.x-k8s.io/v1beta1
kind: Cluster
metadata:
  name: capi-quickstart
spec:
  clusterNetwork:
    pods:
      cidrBlocks: ["192.168.0.0/16"]
    services:
      cidrBlocks: ["10.96.0.0/12"]
  controlPlaneRef:
    apiVersion: controlplane.cluster.x-k8s.io/v1beta1
    kind: KubeadmControlPlane
    name: capi-quickstart-control-plane
  infrastructureRef:
    apiVersion: infrastructure.cluster.x-k8s.io/v1beta1
    kind: DockerCluster
    name: capi-quickstart
---
apiVersion: infrastructure.cluster.x-k8s.io/v1beta1
kind: DockerCluster
metadata:
  name: capi-quickstart
---
apiVersion: controlplane.cluster.x-k8s.io/v1beta1
kind: KubeadmControlPlane
metadata:
  name: capi-quickstart-control-plane
spec:
  replicas: 1
  version: v1.28.0
  machineTemplate:
    infrastructureRef:
      apiVersion: infrastructure.cluster.x-k8s.io/v1beta1
      kind: DockerMachineTemplate
      name: capi-quickstart-control-plane
---
apiVersion: cluster.x-k8s.io/v1beta1
kind: MachineDeployment
metadata:
  name: capi-quickstart-md-0
spec:
  clusterName: capi-quickstart
  replicas: 2
  selector:
    matchLabels: null
  template:
    spec:
      bootstrap:
        configRef:
          apiVersion: bootstrap.cluster.x-k8s.io/v1beta1
          kind: KubeadmConfigTemplate
          name: capi-quickstart-md-0
      clusterName: capi-quickstart
      infrastructureRef:
        apiVersion: infrastructure.cluster.x-k8s.io/v1beta1
        kind: DockerMachineTemplate
        name: capi-quickstart-md-0
      version: v1.28.0
```

#### 4.3 Workload Cluster ìƒì„±

```bash
# í´ëŸ¬ìŠ¤í„° ìƒì„±
kubectl apply -f capi-quickstart.yaml

# ìƒì„± ì§„í–‰ ëª¨ë‹ˆí„°ë§
clusterctl describe cluster capi-quickstart
kubectl get cluster
kubectl get kubeadmcontrolplane
kubectl get machinedeployment
kubectl get machines

# ìƒì„¸ ë¡œê·¸
kubectl get events --sort-by='.lastTimestamp' -A
```

#### 4.4 Workload Cluster ì ‘ì†

```bash
# Workload Cluster kubeconfig ê°€ì ¸ì˜¤ê¸°
clusterctl get kubeconfig capi-quickstart > capi-quickstart.kubeconfig

# CNI ì„¤ì¹˜ (Calico)
kubectl --kubeconfig=./capi-quickstart.kubeconfig \
  apply -f https://raw.githubusercontent.com/projectcalico/calico/v3.26.1/manifests/calico.yaml

# Workload Cluster ë…¸ë“œ í™•ì¸
kubectl --kubeconfig=./capi-quickstart.kubeconfig get nodes
# NAME                                             STATUS   ROLES           AGE   VERSION
# capi-quickstart-control-plane-xxxxx              Ready    control-plane   5m    v1.28.0
# capi-quickstart-md-0-xxxxx-yyyyy                 Ready    <none>          3m    v1.28.0
# capi-quickstart-md-0-xxxxx-zzzzz                 Ready    <none>          3m    v1.28.0
```

### 5. Cluster ê´€ë¦¬

#### 5.1 Worker ë…¸ë“œ ìŠ¤ì¼€ì¼ë§

```bash
# MachineDeployment ìŠ¤ì¼€ì¼
kubectl scale machinedeployment capi-quickstart-md-0 --replicas=5

# í™•ì¸
kubectl get machines
clusterctl describe cluster capi-quickstart
```

#### 5.2 Control Plane ìŠ¤ì¼€ì¼ë§ (HA)

```bash
# KubeadmControlPlane ìŠ¤ì¼€ì¼
kubectl patch kubeadmcontrolplane capi-quickstart-control-plane \
  --type merge -p '{"spec":{"replicas":3}}'

# í™•ì¸
kubectl get kubeadmcontrolplane
kubectl get machines -l cluster.x-k8s.io/control-plane
```

#### 5.3 Kubernetes ë²„ì „ ì—…ê·¸ë ˆì´ë“œ

```bash
# Control Plane ì—…ê·¸ë ˆì´ë“œ
kubectl patch kubeadmcontrolplane capi-quickstart-control-plane \
  --type merge -p '{"spec":{"version":"v1.29.0"}}'

# Worker ì—…ê·¸ë ˆì´ë“œ
kubectl patch machinedeployment capi-quickstart-md-0 \
  --type merge -p '{"spec":{"template":{"spec":{"version":"v1.29.0"}}}}'

# ì§„í–‰ ìƒí™© ëª¨ë‹ˆí„°ë§
kubectl get machines -w
clusterctl describe cluster capi-quickstart
```

#### 5.4 Cluster ì‚­ì œ

```bash
# Workload Cluster ì‚­ì œ
kubectl delete cluster capi-quickstart

# í™•ì¸ (ëª¨ë“  ë¦¬ì†ŒìŠ¤ ìë™ ì‚­ì œ)
kubectl get machines
kubectl get cluster
```

---

## ğŸ’¡ í•µì‹¬ ê°œë… ì •ë¦¬

### 1. RKE2ì˜ ë³´ì•ˆ ê°•í™” í¬ì¸íŠ¸

#### 1.1 FIPS 140-2 ì¤€ìˆ˜

```mermaid
graph LR
    A[FIPS 140-2<br/>ìš”êµ¬ì‚¬í•­] --> B[ìŠ¹ì¸ëœ<br/>ì•”í˜¸í™” ëª¨ë“ˆ]
    B --> C[TLS 1.2+]
    B --> D[AES-256]
    B --> E[RSA 2048+]
    C --> F[RKE2<br/>ì¸ì¦ëœ ë°”ì´ë„ˆë¦¬]
    D --> F
    E --> F
```

**ì¤€ìˆ˜ í•­ëª©**:
- âœ… NIST ìŠ¹ì¸ ì•”í˜¸í™” ì•Œê³ ë¦¬ì¦˜ë§Œ ì‚¬ìš©
- âœ… FIPS 140-2 ì¸ì¦ ì•”í˜¸í™” ë¼ì´ë¸ŒëŸ¬ë¦¬ (BoringCrypto)
- âœ… TLS 1.2 ì´ìƒ ê°•ì œ
- âœ… ì•ˆì „í•˜ì§€ ì•Šì€ ì•”í˜¸í™” ë¹„í™œì„±í™”

#### 1.2 CIS Benchmark ê¸°ë³¸ ì¤€ìˆ˜

```yaml
# profile: cis-1.23 ì ìš© ì‹œ ìë™ ì„¤ì •

# 1. Pod Security
PodSecurityStandard: restricted

# 2. RBAC
# - ìµœì†Œ ê¶Œí•œ ì›ì¹™
# - system:masters ê·¸ë£¹ ì œí•œ

# 3. Network Policies
# - ê¸°ë³¸ Deny
# - ëª…ì‹œì  Allowë§Œ í—ˆìš©

# 4. Audit Logging
# - API ìš”ì²­ ëª¨ë‘ ê¸°ë¡
# - ë¯¼ê° ì •ë³´ ë§ˆìŠ¤í‚¹

# 5. Kubelet ê°•í™”
# - Anonymous auth ë¹„í™œì„±í™”
# - Authorization mode: Webhook
# - Read-only port ë¹„í™œì„±í™”
```

#### 1.3 SELinux/AppArmor í†µí•©

```bash
# RKE2ëŠ” ìë™ìœ¼ë¡œ ë³´ì•ˆ í”„ë¡œí•„ ì ìš©
# - Containerë³„ ê²©ë¦¬
# - Host íŒŒì¼ì‹œìŠ¤í…œ ì ‘ê·¼ ì œí•œ
# - Capabilities ìµœì†Œí™”
```

### 2. Cluster APIì˜ ì¥ì 

#### 2.1 ì„ ì–¸ì  ì¸í”„ë¼ ê´€ë¦¬

```yaml
# ê¸°ì¡´ ë°©ì‹ (ëª…ë ¹í˜•)
# 1. terraform apply (ì¸í”„ë¼ ìƒì„±)
# 2. ansible-playbook (K8s ì„¤ì¹˜)
# 3. kubectl apply (ì›Œí¬ë¡œë“œ ë°°í¬)

# CAPI ë°©ì‹ (ì„ ì–¸ì )
apiVersion: cluster.x-k8s.io/v1beta1
kind: Cluster
metadata:
  name: prod-cluster
spec:
  # ëª¨ë“  ê²ƒì´ í•˜ë‚˜ì˜ YAMLë¡œ!
```

**ì¥ì **:
- âœ… GitOps ì¹œí™”ì  (Git = Single Source of Truth)
- âœ… ì¬í˜„ ê°€ëŠ¥ (ë™ì¼í•œ YAML = ë™ì¼í•œ í´ëŸ¬ìŠ¤í„°)
- âœ… ë²„ì „ ê´€ë¦¬ (Git History)
- âœ… ìë™í™” (CI/CD í†µí•©)

#### 2.2 ë©€í‹° í´ë¼ìš°ë“œ ì¼ê´€ì„±

```mermaid
graph TB
    subgraph "ë™ì¼í•œ CAPI YAML"
        YAML[cluster.yaml]
    end

    YAML -->|Provider: AWS| AWS[AWS EKS]
    YAML -->|Provider: Azure| AZURE[Azure AKS]
    YAML -->|Provider: GCP| GCP[GCP GKE]
    YAML -->|Provider: vSphere| VSPHERE[vSphere]
```

**ì¥ì **:
- âœ… ë™ì¼í•œ APIë¡œ ëª¨ë“  í´ë¼ìš°ë“œ ê´€ë¦¬
- âœ… ë©€í‹° í´ë¼ìš°ë“œ ì „ëµ ìš©ì´
- âœ… Vendor Lock-in íšŒí”¼

#### 2.3 Self-Healing

```yaml
# MachineHealthCheckë¡œ ìë™ ë³µêµ¬
apiVersion: cluster.x-k8s.io/v1beta1
kind: MachineHealthCheck
metadata:
  name: worker-health-check
spec:
  clusterName: capi-quickstart
  maxUnhealthy: 40%
  nodeStartupTimeout: 10m
  unhealthyConditions:
    - type: Ready
      status: Unknown
      timeout: 5m
    - type: Ready
      status: "False"
      timeout: 5m
```

**ìë™ ë³µêµ¬**:
- âœ… Unhealthy ë…¸ë“œ ìë™ ê°ì§€
- âœ… ìƒˆ ë…¸ë“œë¡œ ìë™ êµì²´
- âœ… Workload ìë™ ì¬ìŠ¤ì¼€ì¤„ë§

### 3. RKE2 vs K3s vs kubeadm

| íŠ¹ì§• | RKE2 | K3s | kubeadm |
|------|------|-----|---------|
| **ëŒ€ìƒ í™˜ê²½** | Enterprise, ì •ë¶€ | Edge, IoT, Dev | ì»¤ìŠ¤í„°ë§ˆì´ì§• í•„ìš” ì‹œ |
| **ë³´ì•ˆ ì¤€ìˆ˜** | FIPS, CIS ê¸°ë³¸ | ì„ íƒì  | ìˆ˜ë™ ì„¤ì • |
| **ë°”ì´ë„ˆë¦¬ í¬ê¸°** | ~200MB | ~50MB | ë¶„ì‚° ë‹¤ìš´ë¡œë“œ |
| **Container Runtime** | containerd (ë‚´ì¥) | containerd (ë‚´ì¥) | ë³„ë„ ì„¤ì¹˜ |
| **ì„¤ì¹˜ ë³µì¡ë„** | ë§¤ìš° ì‰¬ì›€ | ë§¤ìš° ì‰¬ì›€ | ì¤‘ê°„ |
| **HA êµ¬ì„±** | Embedded etcd | Embedded etcd | ì™¸ë¶€ etcd í•„ìš” |
| **Add-on** | í’ë¶€ (Ingress, LB) | ê¸°ë³¸ (Traefik, LB) | ì—†ìŒ (ìˆ˜ë™) |
| **ë¦¬ì†ŒìŠ¤ ì‚¬ìš©** | ì¤‘ê°„ | ë‚®ìŒ | ì¤‘ê°„ |
| **ì—…ê·¸ë ˆì´ë“œ** | ì‰¬ì›€ (SUC) | ì‰¬ì›€ | ìˆ˜ë™ |

**ì„ íƒ ê°€ì´ë“œ**:
- **RKE2**: ë³´ì•ˆ ì¤€ìˆ˜, í”„ë¡œë•ì…˜, Enterprise
- **K3s**: Edge, ë¦¬ì†ŒìŠ¤ ì œì•½, ë¹ ë¥¸ ë°°í¬
- **kubeadm**: ì™„ì „í•œ ì œì–´, ì»¤ìŠ¤í„°ë§ˆì´ì§•, í•™ìŠµ

---

## ğŸ“ Week 7 í•™ìŠµ ì •ë¦¬

### í•™ìŠµí•œ ë‚´ìš©

**RKE2**:
1. âœ… RKE2ì˜ ë³´ì•ˆ ê°•í™” ê¸°ëŠ¥ (FIPS, CIS, SELinux/AppArmor)
2. âœ… Server/Agent ì•„í‚¤í…ì²˜ ì´í•´
3. âœ… ê°„í¸í•œ ì„¤ì¹˜ ë° êµ¬ì„± (ìŠ¤í¬ë¦½íŠ¸ í•œ ì¤„)
4. âœ… Embedded etcdë¥¼ ì‚¬ìš©í•œ HA êµ¬ì„±
5. âœ… CNI ì„ íƒ (Canal, Cilium, Calico)
6. âœ… System Upgrade Controllerë¥¼ í†µí•œ ìë™ ì—…ê·¸ë ˆì´ë“œ
7. âœ… ì¸ì¦ì„œ ìë™ ê´€ë¦¬

**Cluster API**:
1. âœ… Management vs Workload Cluster ê°œë…
2. âœ… ì„ ì–¸ì  í´ëŸ¬ìŠ¤í„° ê´€ë¦¬ (Infrastructure as Code)
3. âœ… ë©€í‹° í´ë¼ìš°ë“œ ì§€ì› (AWS, Azure, GCP, vSphere)
4. âœ… clusterctlì„ í†µí•œ Provider ê´€ë¦¬
5. âœ… í´ëŸ¬ìŠ¤í„° ìƒì„±, ìŠ¤ì¼€ì¼ë§, ì—…ê·¸ë ˆì´ë“œ, ì‚­ì œ
6. âœ… MachineDeployment, KubeadmControlPlane ë¦¬ì†ŒìŠ¤
7. âœ… GitOps ì›Œí¬í”Œë¡œ í†µí•©

### ì‹¤ìŠµ ì„±ê³¼

**RKE2**:
- HA Server í´ëŸ¬ìŠ¤í„° (3 Servers + 2 Agents) êµ¬ì¶•
- Cilium CNI ì ìš©
- System Upgrade Controllerë¡œ ìë™ ì—…ê·¸ë ˆì´ë“œ
- CIS Profile ì ìš© ë° ê²€ì¦

**Cluster API**:
- Kindë¡œ Management Cluster êµ¬ì„±
- Docker Providerë¡œ Workload Cluster ìƒì„±
- Worker ë…¸ë“œ ìŠ¤ì¼€ì¼ë§ (2 â†’ 5)
- Control Plane HA êµ¬ì„± (1 â†’ 3)
- Kubernetes ë²„ì „ ì—…ê·¸ë ˆì´ë“œ (v1.28.0 â†’ v1.29.0)

### í•µì‹¬ ê°œë…

**RKE2ì˜ í•µì‹¬**:
- **ë³´ì•ˆ ìš°ì„ **: FIPS, CIS ê¸°ë³¸ ì¤€ìˆ˜
- **ê°„í¸í•¨**: ìŠ¤í¬ë¦½íŠ¸ í•œ ì¤„ë¡œ ì„¤ì¹˜
- **í”„ë¡œë•ì…˜ ì¤€ë¹„**: HA, ìë™ ì—…ê·¸ë ˆì´ë“œ, ì¸ì¦ì„œ ê´€ë¦¬

**Cluster APIì˜ í•µì‹¬**:
- **ì„ ì–¸ì **: YAMLë¡œ í´ëŸ¬ìŠ¤í„° ì •ì˜
- **GitOps**: Git = Single Source of Truth
- **ë©€í‹° í´ë¼ìš°ë“œ**: ë™ì¼í•œ API, ë‹¤ì–‘í•œ ì¸í”„ë¼
- **Self-Service**: ê°œë°œìê°€ ì§ì ‘ í´ëŸ¬ìŠ¤í„° ìƒì„±/ê´€ë¦¬

### ë‹¤ìŒ ì£¼ í•™ìŠµ ì˜ˆê³ 

ë‹¤ìŒ ì£¼ì°¨ì—ì„œëŠ” ë‹¤ìŒ ì£¼ì œë¥¼ ë‹¤ë£° ì˜ˆì •ì…ë‹ˆë‹¤:
- Kubernetes ëª¨ë‹ˆí„°ë§ ë° ë¡œê¹…
- Prometheus, Grafana ìŠ¤íƒ
- EFK/ELK ìŠ¤íƒ
- ë¶„ì‚° ì¶”ì  (Jaeger, Tempo)

---

**ì‘ì„±ì¼**: 2026-02-21
**í•™ìŠµ ì£¼ì œ**: RKE2 & Cluster API
**ì‹¤ìŠµ í™˜ê²½**: VirtualBox, Ubuntu 22.04, RKE2 v1.28.x, Cluster API v1.6.x
